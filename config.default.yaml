# AI RPG Configuration Template
# Copy this file to config.yaml and update with your settings

server:
  port: 7777
  host: 0.0.0.0 # Use localhost for local development, 0.0.0.0 for external access

# OpenAI-compatible API configuration
ai:
  # API endpoint URL (examples):
  # OpenAI: "https://api.openai.com/v1"
  # LocalAI: "http://localhost:8080/v1"
  # Ollama: "http://localhost:11434/v1"
  # nano-gpt: "https://nano-gpt.com/api/v1"
  endpoint: "https://nano-gpt.com/api/v1"

  # Your API key (keep this secure!)
  apiKey: "your-api-key-here"

  # Model to use (examples):
  # OpenAI: "gpt-3.5-turbo", "gpt-4"
  # LocalAI: depends on your models
  # Ollama: "llama2", "mistral", etc.
  model: zai-org/GLM-4.5-FP8"

  # Optional: Additional parameters
  maxTokens: 2000
  temperature: 0.7
  baseTimeoutSeconds: 120

imagegen:
  enabled: true
  engine: comfyui
  api_template: sdxl_illustrious.json.njk

  # Checkpoint is relative to the ComfyUI models/
  checkpoint: "sdxl/QuillworksIllustrious_QuillworksV15.safetensors"

  prompt_generator_templates:
    character: player-portrait-illustrious.xml.njk
    item: item-image-illustrious.xml.njk
    location: location-image-illustrious.xml.njk
    scenery: scenery-image-illustrious.xml.njk
  default_negative_prompt: indistinct, poor quality, blurry, low detail
  megapixels: 1.0
  server:
    host: localhost
    port: 8188
  default_settings:
    image:
      width: 1024
      height: 1024
      seed: 42
  location_settings:
    image:
      width: 1280
      height: 720
random_event_frequency:
  common: 0.04
  rare: 0.01
# Game Master configuration
gamemaster:
  # Fallback system prompt
  promptTemplate: "gamemaster.njk"
regions:
  minLocations: 2
  maxLocations: 3
locations:
  maxNpcs: 4
  maxHostiles: 4
  maxItems: 4
  maxScenery: 4
  levelVariation: 3

# Number of events to check concurrently when processing text. Omit to do them all.
# A lower number makes it easier for the AI but is slower and will use more tokens/requests.
# You can omit this for sophisticated models that can handle more complex prompts.
events_to_check_concurrently: 10

# This can be: never, unexplored_regions, unexplored_locations, or always
check_move_plausibility: unexplored_locations

# Mostly to speed up testing and development - prevent certain types of generation
omit_npc_generation: false
omit_item_generation: false
summaries:
  enabled: true
  summarize_on_load: false
  batch_size: 30
  summary_word_length: 12
  max_unsummarized_log_entries: 100
generate_memory_interval: 10
max_memories_to_recall: 10
